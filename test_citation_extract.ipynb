{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cuda', index=0), ['law', 'citation'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from gliner import GLiNER\n",
    "import torch\n",
    "# @title Fast Mertics\n",
    "\n",
    "# Load the test.json file\n",
    "with open('citation_data/test.json', 'r') as file:\n",
    "    test_data = json.load(file)\n",
    "\n",
    "'''\n",
    "with open('data/filtered_ner_training_data.json', 'r') as file:\n",
    "    annotated_data = json.load(file)\n",
    "'''\n",
    "\n",
    "# Extract all labels from each example\n",
    "\n",
    "def get_all_labels(data):\n",
    "    all_labels = []\n",
    "    for example in data:\n",
    "        ner_data = example.get(\"ner\", [])\n",
    "        for entity in ner_data:\n",
    "            label = entity[2]  # Assuming the label is the third element in the entity list\n",
    "            if label not in all_labels:\n",
    "                all_labels.append(label)\n",
    "    return all_labels\n",
    "\n",
    "all_test_labels = get_all_labels(test_data)\n",
    "\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device, all_test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json not found in /home/ubuntu/mert/dslab/models_citation/checkpoint-50000\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_anonv0_path = 'models_citation/checkpoint-50000'\n",
    "\n",
    "model_anonv0 = GLiNER.from_pretrained(model_anonv0_path, load_tokenizer=True, local_files_only=True)\n",
    "model_anonv0 = model_anonv0.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.93\n",
      "P: 92.85%\tR: 92.89%\tF1: 92.87%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results, f1 = model_anonv0.evaluate(test_data, flat_ner=True, threshold=0.5, batch_size=1, entity_types=all_test_labels)\n",
    "output_info = f\"F1 Score: {f1:.2f}\" + \"\\n\" + results\n",
    "print(output_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "683762b4224643dea3a4431caa5d8484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/dslab/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:560: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_baseline1 = GLiNER.from_pretrained('knowledgator/gliner-multitask-large-v0.5')\n",
    "model_baseline1 = model_baseline1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.35\n",
      "P: 35.95%\tR: 33.29%\tF1: 34.57%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results, f1 = model_baseline1.evaluate(test_data, flat_ner=True, threshold=0.5, batch_size=1, entity_types=all_test_labels)\n",
    "output_info = f\"F1 Score: {f1:.2f}\" + \"\\n\" + results\n",
    "print(output_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19769e77ba364c549ba10c78238d2b88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# urchade/gliner_multi_pii-v1\n",
    "model_baseline2 = GLiNER.from_pretrained('urchade/gliner_multi_pii-v1')\n",
    "model_baseline2 = model_baseline2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.43\n",
      "P: 31.75%\tR: 66.91%\tF1: 43.07%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results, f1 = model_baseline2.evaluate(test_data_baseline, flat_ner=True, threshold=0.5, batch_size=1, entity_types=all_test_baseline_labels)\n",
    "output_info = f\"F1 Score: {f1:.2f}\" + \"\\n\" + results\n",
    "print(output_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do Inference on one sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('11 ) unter anderem strafbar, wer sich die Marke eines anderen anmasst oder diese nachmacht oder nachahmt ( lit. a ) oder wer unter der angemassten, nachgemachten oder nachgeahmten Marke Waren in Verkehr setzt, solche Waren anbietet, ein -, aus - oder durchführt, sie zum Zweck des Inverkehrbringens lagert oder für sie wirbt ( lit. b ). Vor diesem Hintergrund ist nicht ohne Weiteres klar, worin das Interesse der Beschwerdeführerin an der Herausgabe dieser nur sehr begrenzt verkehrsfähigen Gegenstände liegen soll. Auch wenn sie als beschuldigte Person prinzipiell zur Beschwerde in Strafsachen legitimiert ist, hätte sie sich daher dazu äussern müssen, woraus sie ihr rechtlich geschütztes Interesse an der Anfechtung der Einziehungen ableitet. Wo sie nicht offensichtlich ist, bezieht sich die Begründungsobliegenheit von Art. 42 Abs. 2 BGG auch auf die Legitimation ( vgl. BGE 141 IV 1 E. 1. 1 mit Hinweisen; Urteil 7B_183 / 2023 vom 26. Juli 2023 E. 1. 3 ). Da die Beschwerdeführerin dieser Obliegenheit nicht nachkommt, erübrigt sich ein Eintreten auf die Beschwerde in diesem Punkt. 11. Schliesslich macht die Beschwerdeführerin auch hinsichtlich der Zivilansprüche in den Dossiers Michal Lutz und Belal Fernandez eine Verletzung der gehörsrechtlichen Begründungspflicht geltend. 11. 1. Im Fall Michal Lutz, so die Beschwerdeführerin konkret, befasse sich die Vorinstanz nicht mit ihrem Einwand, wonach die Zivilforderung ungenügend beziffert sei und Gesamthandsgemeinschaften übereinstimmende Rechtsbegehren stellen müssten. Gleiches gelte für den Einwand,',\n",
       " [[212, 213, 'a_name'], [230, 231, 'a_name'], [215, 216, 'a_name']])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def join_tokens(tokens):\n",
    "    # code from Gliner_Studio: https://colab.research.google.com/drive/1Kl3TrpiGBpMw569ek_AL6Ee3uqBK-Gfw?usp=sharing\n",
    "    # Joining tokens with space, but handling special characters correctly\n",
    "    text = \"\"\n",
    "    for token in tokens:\n",
    "        if token in {\",\", \".\", \"!\", \"?\", \":\", \";\", \"...\"}:\n",
    "            text = text.rstrip() + token\n",
    "        else:\n",
    "            text += \" \" + token\n",
    "    return text.strip()\n",
    "\n",
    "example_index = 0\n",
    "text = join_tokens(test_data[example_index][\"tokenized_text\"])\n",
    "text, test_data[example_index][\"ner\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_name: ['Michal', 'Lutz']\n",
      "a_name: ['Michal', 'Lutz']\n",
      "a_name: ['Belal', 'Fernandez']\n"
     ]
    }
   ],
   "source": [
    "def view(tokenized_text, ners):\n",
    "    for ner in ners:\n",
    "        start, end, label = ner\n",
    "        print(f\"{label}: {tokenized_text[start:end+1]}\")\n",
    "\n",
    "view(test_data[example_index][\"tokenized_text\"], test_data[example_index][\"ner\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a_name', 'a_organisation', 'a_place']\n",
      "Expected Entities:\n",
      "a_name: ['Chloé', 'Fendt-Newlin']\n",
      "a_name: ['Chloé', 'Fendt-Newlin']\n",
      "a_name: ['Chloé', 'Fendt-Newlin']\n",
      "a_name: ['Chloé', 'Fendt-Newlin']\n",
      "\n",
      "Predicted Entities:\n",
      "Chloé Fendt-Newlin => a_name\n",
      "Chloé Fendt-Newlin => a_name\n",
      "Chloé Fendt-Newlin => a_name\n",
      "Chloé Fendt-Newlin => a_name\n"
     ]
    }
   ],
   "source": [
    "example_index = 15\n",
    "\n",
    "text = join_tokens(test_data[example_index][\"tokenized_text\"])\n",
    "expected_ner = test_data[example_index][\"ner\"]\n",
    "\n",
    "# Labels for entity prediction\n",
    "labels = all_test_labels\n",
    "print(labels)\n",
    "\n",
    "# Perform entity prediction\n",
    "entities = model_anonv0.predict_entities(text, labels, threshold=0.5)\n",
    "\n",
    "# Display predicted entities and their labels\n",
    "print(\"Expected Entities:\")\n",
    "view(test_data[example_index][\"tokenized_text\"], test_data[example_index][\"ner\"])\n",
    "\n",
    "print(\"\\nPredicted Entities:\")\n",
    "for entity in entities:\n",
    "    print(entity[\"text\"], \"=>\", entity[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text for entity prediction\n",
    "text = random_rows.iloc[0][\"text\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a_name': 49722, 'a_organisation': 6945, 'a_place': 1897}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count all labels in the test dataset\n",
    "def count_labels(data):\n",
    "    label_count = {}\n",
    "    for example in data:\n",
    "        ner_data = example.get(\"ner\", [])\n",
    "        for entity in ner_data:\n",
    "            label = entity[2]  # Assuming the label is the third element in the entity list\n",
    "            if label not in label_count:\n",
    "                label_count[label] = 0\n",
    "            label_count[label] += 1\n",
    "    return label_count\n",
    "\n",
    "label_count = count_labels(test_data)\n",
    "label_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_name 13902\n",
      "a_organisation 2817\n",
      "a_place 1121\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# create test data for each specific labels (filter data points for a specific label, throw out examples that do not have the label)\n",
    "def create_test_data_for_label(data, label):\n",
    "    test_data_label = []\n",
    "    for example in data:\n",
    "        ner_data = example.get(\"ner\", [])\n",
    "        new_ners = []\n",
    "        for entity in ner_data:\n",
    "            if entity[2] == label:\n",
    "                new_ners.append(entity)\n",
    "        if len(new_ners) > 0:\n",
    "            test_data_label.append({\"tokenized_text\": example[\"tokenized_text\"], \"ner\": new_ners})\n",
    "    return test_data_label\n",
    "\n",
    "# create test data for each specific labels\n",
    "labelled_test_data = dict() \n",
    "for label in all_test_labels:\n",
    "    labelled_test_data[label] = create_test_data_for_label(test_data, label)\n",
    "\n",
    "for k,v in labelled_test_data.items():\n",
    "    print(k, len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokenized_text': ['Participants',\n",
       "  'à',\n",
       "  'la',\n",
       "  'procédure',\n",
       "  'Stefan',\n",
       "  'Michaud',\n",
       "  ',',\n",
       "  'représenté',\n",
       "  'par',\n",
       "  'Me',\n",
       "  'Manuela',\n",
       "  'Ryter',\n",
       "  'Godel',\n",
       "  ',',\n",
       "  'avocate',\n",
       "  ',',\n",
       "  'recourant',\n",
       "  ',',\n",
       "  'contre',\n",
       "  'Ministère',\n",
       "  'public',\n",
       "  'central',\n",
       "  'du',\n",
       "  'canton',\n",
       "  'de',\n",
       "  'Vaud',\n",
       "  ',',\n",
       "  'avenue',\n",
       "  'de',\n",
       "  'Longemalle',\n",
       "  '1',\n",
       "  ',',\n",
       "  '1020',\n",
       "  'Renens',\n",
       "  'VD',\n",
       "  ',',\n",
       "  'intimé',\n",
       "  '.',\n",
       "  'Objet',\n",
       "  'Ordonnance',\n",
       "  'de',\n",
       "  'classement',\n",
       "  '(',\n",
       "  'mise',\n",
       "  'en',\n",
       "  'danger',\n",
       "  'de',\n",
       "  'la',\n",
       "  'vie',\n",
       "  'd',\n",
       "  \"'\",\n",
       "  'autrui',\n",
       "  ',',\n",
       "  'abus',\n",
       "  'd',\n",
       "  \"'\",\n",
       "  'autorité',\n",
       "  ')',\n",
       "  ',',\n",
       "  'recours',\n",
       "  'contre',\n",
       "  'l',\n",
       "  \"'\",\n",
       "  'arrêt',\n",
       "  'du',\n",
       "  'Tribunal',\n",
       "  'cantonal',\n",
       "  'du',\n",
       "  'canton',\n",
       "  'de',\n",
       "  'Vaud',\n",
       "  ',',\n",
       "  'Chambre',\n",
       "  'des',\n",
       "  'recours',\n",
       "  'pénale',\n",
       "  ',',\n",
       "  'du',\n",
       "  '17',\n",
       "  'février',\n",
       "  '2020',\n",
       "  '(',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '[',\n",
       "  'PE1',\n",
       "  ']',\n",
       "  ')',\n",
       "  '.',\n",
       "  'Faits',\n",
       "  ':',\n",
       "  'A',\n",
       "  '.',\n",
       "  'Le',\n",
       "  '7',\n",
       "  'mars',\n",
       "  '2019',\n",
       "  ',',\n",
       "  'à',\n",
       "  'Bottmingen',\n",
       "  ',',\n",
       "  'Kalia',\n",
       "  'Domenjoz',\n",
       "  'et',\n",
       "  'Stefan',\n",
       "  'Michaud',\n",
       "  ',',\n",
       "  'dans',\n",
       "  'une',\n",
       "  'BMW',\n",
       "  'grise',\n",
       "  'conduite',\n",
       "  'par',\n",
       "  'ce',\n",
       "  'dernier',\n",
       "  ',',\n",
       "  'ont',\n",
       "  'été',\n",
       "  'interpellés',\n",
       "  'dans',\n",
       "  'la',\n",
       "  'rue',\n",
       "  'du',\n",
       "  'Stand',\n",
       "  ',',\n",
       "  'qui',\n",
       "  'se',\n",
       "  'termine',\n",
       "  'en',\n",
       "  'cul-de-sac',\n",
       "  ',',\n",
       "  'après',\n",
       "  'avoir',\n",
       "  'été',\n",
       "  'suivis',\n",
       "  'depuis',\n",
       "  'le',\n",
       "  'centre',\n",
       "  'de',\n",
       "  'Bottmingen',\n",
       "  'par',\n",
       "  'la',\n",
       "  'patrouille',\n",
       "  'de',\n",
       "  'police',\n",
       "  'Sami',\n",
       "  'Brazerol',\n",
       "  ',',\n",
       "  'composée',\n",
       "  'des',\n",
       "  'agents',\n",
       "  'Léone',\n",
       "  'Martin',\n",
       "  'et',\n",
       "  'Yvonne',\n",
       "  'Grob',\n",
       "  '.',\n",
       "  'Les',\n",
       "  'deux',\n",
       "  'policiers',\n",
       "  'ont',\n",
       "  'fait',\n",
       "  'usage',\n",
       "  'de',\n",
       "  'leurs',\n",
       "  'armes',\n",
       "  '.',\n",
       "  'Ils',\n",
       "  'ont',\n",
       "  'ensuite',\n",
       "  'été',\n",
       "  'rejoints',\n",
       "  'par',\n",
       "  'une',\n",
       "  'autre',\n",
       "  'patrouille',\n",
       "  ',',\n",
       "  'composée',\n",
       "  'des',\n",
       "  'agents',\n",
       "  'Bernadette',\n",
       "  'Drees',\n",
       "  'et',\n",
       "  'Heinz',\n",
       "  'Eriksen',\n",
       "  '.',\n",
       "  'Le',\n",
       "  'même',\n",
       "  'jour',\n",
       "  ',',\n",
       "  'une',\n",
       "  'instruction',\n",
       "  'pénale',\n",
       "  'a',\n",
       "  'été',\n",
       "  'ouverte',\n",
       "  'sous',\n",
       "  'référence',\n",
       "  'PE2',\n",
       "  'par',\n",
       "  'le',\n",
       "  'Ministère',\n",
       "  'public',\n",
       "  'de',\n",
       "  'l',\n",
       "  \"'\",\n",
       "  'arrondissement',\n",
       "  'de',\n",
       "  'l',\n",
       "  \"'\",\n",
       "  'Est',\n",
       "  'vaudois',\n",
       "  'contre',\n",
       "  'Kalia',\n",
       "  'Domenjoz',\n",
       "  'et',\n",
       "  'Stefan',\n",
       "  'Michaud',\n",
       "  'en',\n",
       "  'raison',\n",
       "  'de',\n",
       "  'la',\n",
       "  'course-poursuite',\n",
       "  'qui',\n",
       "  's',\n",
       "  \"'\",\n",
       "  'est',\n",
       "  'déroulée',\n",
       "  'entre',\n",
       "  'le',\n",
       "  'centre',\n",
       "  'de',\n",
       "  'Bottmingen',\n",
       "  'et',\n",
       "  'la',\n",
       "  'rue',\n",
       "  'du',\n",
       "  'Stand',\n",
       "  '.',\n",
       "  'Lors',\n",
       "  'de',\n",
       "  'leurs',\n",
       "  'auditions',\n",
       "  'd',\n",
       "  \"'\",\n",
       "  'arrestation',\n",
       "  'respectives',\n",
       "  'du',\n",
       "  '9',\n",
       "  'mars',\n",
       "  '2019',\n",
       "  ',',\n",
       "  'Kalia',\n",
       "  'Domenjoz',\n",
       "  'et',\n",
       "  'Stefan',\n",
       "  'Michaud',\n",
       "  'ont',\n",
       "  'tous',\n",
       "  'deux',\n",
       "  'déposé',\n",
       "  'plainte',\n",
       "  '.',\n",
       "  'Stefan',\n",
       "  'Michaud'],\n",
       " 'ner': [[100, 100, 'a_place'], [140, 140, 'a_place'], [233, 233, 'a_place']]}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_test_data['a_place'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: a_name, Results: P: 99.78%\tR: 99.43%\tF1: 99.60%\n",
      "\n",
      "Label: a_organisation, Results: P: 96.70%\tR: 99.16%\tF1: 97.92%\n",
      "\n",
      "Label: a_place, Results: P: 83.95%\tR: 98.15%\tF1: 90.50%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run evaluation for each label\n",
    "results = {}\n",
    "\n",
    "for label, data in labelled_test_data.items():\n",
    "    results[label], f1 = model_anonv0.evaluate(data, flat_ner=True, threshold=0.5, batch_size=1, entity_types=[label])\n",
    "    print(f\"Label: {label}, Results: {results[label]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: a_name\n",
      "Label: a_organisation\n",
      "Results: P: 97.15%\tR: 99.09%\tF1: 98.11%\n",
      "\n",
      "Label: a_place\n",
      "Results: P: 88.28%\tR: 98.10%\tF1: 92.93%\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# run evaluation for each label\n",
    "results = {}\n",
    "\n",
    "for label, data in labelled_test_data.items():\n",
    "    threshold = 0.5\n",
    "    print(f\"Label: {label}\")\n",
    "    if label == \"a_name\":\n",
    "        continue\n",
    "    else:\n",
    "        threshold = 0.95\n",
    "    results[label], f1 = model_anonv0.evaluate(data, flat_ner=True, threshold=threshold, batch_size=1, entity_types=[label])\n",
    "    print(f\"Results: {results[label]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>La société Énergie Verte SA et l'association S...</td>\n",
       "      <td>[Énergie Verte SA, Solidarité Environnement, L...</td>\n",
       "      <td>[a_organisation, a_organisation, a_place]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Madame Claire Dupont et Monsieur Jean-Louis Ma...</td>\n",
       "      <td>[Claire Dupont, Jean-Louis Martin]</td>\n",
       "      <td>[a_name, a_name]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Un contrat a été signé entre l'organisation Mé...</td>\n",
       "      <td>[Médecins Sans Frontières, Conseil Municipal d...</td>\n",
       "      <td>[a_organisation, a_place]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Monsieur Paul Durand, représentant de l'associ...</td>\n",
       "      <td>[Paul Durand, Culture et Patrimoine]</td>\n",
       "      <td>[a_name, a_organisation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>La Fondation pour la Recherche Médicale et l'u...</td>\n",
       "      <td>[Fondation pour la Recherche Médicale, univers...</td>\n",
       "      <td>[a_organisation, a_organisation, a_place]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  La société Énergie Verte SA et l'association S...   \n",
       "1  Madame Claire Dupont et Monsieur Jean-Louis Ma...   \n",
       "2  Un contrat a été signé entre l'organisation Mé...   \n",
       "3  Monsieur Paul Durand, représentant de l'associ...   \n",
       "4  La Fondation pour la Recherche Médicale et l'u...   \n",
       "\n",
       "                                            entities  \\\n",
       "0  [Énergie Verte SA, Solidarité Environnement, L...   \n",
       "1                 [Claire Dupont, Jean-Louis Martin]   \n",
       "2  [Médecins Sans Frontières, Conseil Municipal d...   \n",
       "3               [Paul Durand, Culture et Patrimoine]   \n",
       "4  [Fondation pour la Recherche Médicale, univers...   \n",
       "\n",
       "                                      labels  \n",
       "0  [a_organisation, a_organisation, a_place]  \n",
       "1                           [a_name, a_name]  \n",
       "2                  [a_organisation, a_place]  \n",
       "3                   [a_name, a_organisation]  \n",
       "4  [a_organisation, a_organisation, a_place]  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "ood_data = dict()\n",
    "keys = ['french', 'german', 'italian']\n",
    "\n",
    "for key in keys:\n",
    "    ood_data[key] = pd.read_csv(f'data/{key}_ood.csv')\n",
    "    # read entities and labels with ast.literal_eval\n",
    "    ood_data[key]['entities'] = ood_data[key]['entities'].apply(lambda x: ast.literal_eval(x))\n",
    "    ood_data[key]['labels'] = ood_data[key]['labels'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "ood_data['french'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: french\n",
      "Text: Madame Anne Leroy et Monsieur Jacques Rolland ont été choisis pour présider le comité de l'événement.\n",
      "Predicted Entities:\n",
      "Anne Leroy => a_name\n",
      "Jacques Rolland => a_name\n",
      "True Entities:\n",
      "Anne Leroy\n",
      "Jacques Rolland\n",
      "\n",
      "\n",
      "Text: La collaboration entre le Parc National des Pyrénées et le Ministère de la Culture a été officialisée.\n",
      "Predicted Entities:\n",
      "True Entities:\n",
      "Parc National des Pyrénées\n",
      "Ministère de la Culture\n",
      "\n",
      "\n",
      "Text: Le contrat entre l'entreprise SolarFrance et la Région PACA a été finalisé.\n",
      "Predicted Entities:\n",
      "SolarFrance => a_organisation\n",
      "True Entities:\n",
      "SolarFrance\n",
      "Région PACA\n",
      "\n",
      "\n",
      "Text: Le groupe Développement Durable et la ville de Rouen ont validé leur partenariat pour l'année à venir.\n",
      "Predicted Entities:\n",
      "Développement Durable => a_organisation\n",
      "Rouen => a_place\n",
      "True Entities:\n",
      "Développement Durable\n",
      "ville de Rouen\n",
      "Rouen\n",
      "\n",
      "\n",
      "Text: Le contrat entre l'association Humanité et Progrès et l'Université de Strasbourg a été ratifié sans amendement.\n",
      "Predicted Entities:\n",
      "Strasbourg => a_place\n",
      "True Entities:\n",
      "Humanité et Progrès\n",
      "Université de Strasbourg\n",
      "Strasbourg\n",
      "\n",
      "\n",
      "Key: german\n",
      "Text: Herr Dr. Wolfgang Müller wurde als Ansprechpartner für das Projekt der Stadtverwaltung Düsseldorf benannt.\n",
      "Predicted Entities:\n",
      "Wolfgang Müller => a_name\n",
      "True Entities:\n",
      "Dr. Wolfgang Müller\n",
      "Stadtverwaltung Düsseldorf\n",
      "\n",
      "\n",
      "Text: Der Verein Naturfreunde Deutschland e.V. und die Umweltgruppe TerraVerde kooperieren bei einem nationalen Naturschutzprojekt.\n",
      "Predicted Entities:\n",
      "TerraVerde => a_organisation\n",
      "True Entities:\n",
      "Naturfreunde Deutschland e.V.\n",
      "Umweltgruppe TerraVerde\n",
      "\n",
      "\n",
      "Text: Zwischen Herrn Paul Schröder und der Gesundheitsgenossenschaft Nord eG wurde in Kiel ein Vertrag geschlossen.\n",
      "Predicted Entities:\n",
      "Paul Schröder => a_name\n",
      "True Entities:\n",
      "Paul Schröder\n",
      "Gesundheitsgenossenschaft Nord eG\n",
      "Kiel\n",
      "\n",
      "\n",
      "Text: Die Schulung für die Mitarbeiter der Gesundheitszentrum Nord GmbH findet in Frankfurt am Main statt.\n",
      "Predicted Entities:\n",
      "Gesundheitszentrum Nord => a_organisation\n",
      "True Entities:\n",
      "Gesundheitszentrum Nord GmbH\n",
      "Frankfurt am Main\n",
      "\n",
      "\n",
      "Text: Der Vertrag mit der Stiftung Kulturerbe und der Stadtverwaltung Bonn wurde offiziell anerkannt.\n",
      "Predicted Entities:\n",
      "Bonn => a_place\n",
      "True Entities:\n",
      "Stiftung Kulturerbe\n",
      "Stadtverwaltung Bonn\n",
      "\n",
      "\n",
      "Key: italian\n",
      "Text: L'associazione Cuore Verde e l'azienda AgroBio SRL hanno collaborato a un progetto agricolo a Firenze.\n",
      "Predicted Entities:\n",
      "AgroBio => a_organisation\n",
      "True Entities:\n",
      "Cuore Verde\n",
      "AgroBio SRL\n",
      "Firenze\n",
      "\n",
      "\n",
      "Text: La signora Silvia Riva, in rappresentanza della società InnovItalia SRL, ha approvato il progetto.\n",
      "Predicted Entities:\n",
      "Silvia Riva => a_name\n",
      "InnovItalia => a_organisation\n",
      "True Entities:\n",
      "Silvia Riva\n",
      "InnovItalia SRL\n",
      "\n",
      "\n",
      "Text: Il signor Giorgio Pugliese ha partecipato alla riunione come rappresentante di Energia Pulita SRL.\n",
      "Predicted Entities:\n",
      "Giorgio Pugliese => a_name\n",
      "Energia Pulita => a_organisation\n",
      "True Entities:\n",
      "Giorgio Pugliese\n",
      "Energia Pulita SRL\n",
      "\n",
      "\n",
      "Text: L'associazione Cultura per Tutti e il Comune di Firenze hanno lanciato un progetto educativo.\n",
      "Predicted Entities:\n",
      "Firenze => a_place\n",
      "True Entities:\n",
      "Cultura per Tutti\n",
      "Comune di Firenze\n",
      "Firenze\n",
      "\n",
      "\n",
      "Text: Il contratto tra la società BioItalia e il Comune di Torino è stato firmato senza modifiche.\n",
      "Predicted Entities:\n",
      "BioItalia => a_organisation\n",
      "True Entities:\n",
      "BioItalia\n",
      "Comune di Torino\n",
      "Torino\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# take 5 random samples from each ood dataset and test the model\n",
    "\n",
    "for key, data in ood_data.items():\n",
    "    print(f\"Key: {key}\")\n",
    "    data = data.sample(5)\n",
    "    for index, row in data.iterrows():\n",
    "        text = row['text']\n",
    "        labels = row['labels']\n",
    "        entities = model_anonv0.predict_entities(text, labels, threshold=0.5)\n",
    "        print(f\"Text: {text}\")\n",
    "        print(\"Predicted Entities:\")\n",
    "        for entity in entities:\n",
    "            print(entity[\"text\"], \"=>\", entity[\"label\"])\n",
    "        print(\"True Entities:\")\n",
    "        for entry in row['entities']:\n",
    "            print(entry)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dslab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
