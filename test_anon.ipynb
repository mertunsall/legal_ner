{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from gliner import GLiNER\n",
    "import torch\n",
    "# @title Fast Mertics\n",
    "\n",
    "base_dir = 'ood_data'\n",
    "# Load the test.json file\n",
    "with open(f'{base_dir}/test.json', 'r') as file:\n",
    "    test_data = json.load(file)\n",
    "\n",
    "# load the test_data_baseline.json file\n",
    "with open(f'{base_dir}/test_data_baseline.json', 'r') as file:\n",
    "    test_data_baseline = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cuda', index=0),\n",
       " ['a_name', 'a_organisation', 'a_place'],\n",
       " ['person', 'organization', 'place'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract all labels from each example\n",
    "from utils import get_all_labels\n",
    "\n",
    "all_test_labels = get_all_labels(test_data)\n",
    "all_test_baseline_labels = get_all_labels(test_data_baseline)\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device, all_test_labels, all_test_baseline_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json not found in /home/ubuntu/mert/dslab/models_anonymizer/AnonymizerV0_gliner-multitask-large-v0.5\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_anonv0_path = 'models_anonymizer/AnonymizerV0_gliner-multitask-large-v0.5'\n",
    "\n",
    "model_anonv0 = GLiNER.from_pretrained(model_anonv0_path, load_tokenizer=True, local_files_only=True)\n",
    "model_anonv0 = model_anonv0.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.43\n",
      "P: 67.86%\tR: 31.15%\tF1: 42.70%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results, f1 = model_anonv0.evaluate(test_data, flat_ner=True, threshold=0.5, batch_size=1, entity_types=all_test_labels)\n",
    "output_info = f\"F1 Score: {f1:.2f}\" + \"\\n\" + results\n",
    "print(output_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb7447841e154659ae64a0c7ed513ec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/dslab/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:560: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_baseline1 = GLiNER.from_pretrained('knowledgator/gliner-multitask-large-v0.5')\n",
    "model_baseline1 = model_baseline1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.66\n",
      "P: 59.21%\tR: 73.77%\tF1: 65.69%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results, f1 = model_baseline1.evaluate(test_data_baseline, flat_ner=True, threshold=0.5, batch_size=1, entity_types=all_test_baseline_labels)\n",
    "output_info = f\"F1 Score: {f1:.2f}\" + \"\\n\" + results\n",
    "print(output_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9ac1d6f2e394edd9d42bf8ec84184a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# urchade/gliner_multi_pii-v1\n",
    "model_baseline2 = GLiNER.from_pretrained('urchade/gliner_multi_pii-v1')\n",
    "model_baseline2 = model_baseline2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.75\n",
      "P: 66.67%\tR: 85.25%\tF1: 74.82%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results, f1 = model_baseline2.evaluate(test_data_baseline, flat_ner=True, threshold=0.5, batch_size=1, entity_types=all_test_baseline_labels)\n",
    "output_info = f\"F1 Score: {f1:.2f}\" + \"\\n\" + results\n",
    "print(output_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do Inference on one sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_organisation: ['Gitarren', 'AG']\n",
      "a_place: ['Brugg']\n"
     ]
    }
   ],
   "source": [
    "from utils import join_tokens\n",
    "from utils import view\n",
    "\n",
    "example_index = 1\n",
    "text = join_tokens(test_data[example_index][\"tokenized_text\"])\n",
    "\n",
    "view(test_data[example_index][\"tokenized_text\"], test_data[example_index][\"ner\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a_name', 'a_organisation', 'a_place']\n",
      "Expected Entities:\n",
      "a_place: ['Paris']\n",
      "a_name: ['Mark', 'Schneider']\n",
      "\n",
      "Predicted Entities:\n",
      "Mark Schneider => a_name\n"
     ]
    }
   ],
   "source": [
    "example_index = 15\n",
    "\n",
    "text = join_tokens(test_data[example_index][\"tokenized_text\"])\n",
    "expected_ner = test_data[example_index][\"ner\"]\n",
    "\n",
    "# Labels for entity prediction\n",
    "labels = all_test_labels\n",
    "print(labels)\n",
    "\n",
    "# Perform entity prediction\n",
    "entities = model_anonv0.predict_entities(text, labels, threshold=0.5)\n",
    "\n",
    "# Display predicted entities and their labels\n",
    "print(\"Expected Entities:\")\n",
    "view(test_data[example_index][\"tokenized_text\"], test_data[example_index][\"ner\"])\n",
    "\n",
    "print(\"\\nPredicted Entities:\")\n",
    "for entity in entities:\n",
    "    print(entity[\"text\"], \"=>\", entity[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a_name': 76, 'a_organisation': 21, 'a_place': 31}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count all labels in the test dataset\n",
    "def count_labels(data):\n",
    "    label_count = {}\n",
    "    for example in data:\n",
    "        ner_data = example.get(\"ner\", [])\n",
    "        for entity in ner_data:\n",
    "            label = entity[2]  # Assuming the label is the third element in the entity list\n",
    "            if label not in label_count:\n",
    "                label_count[label] = 0\n",
    "            label_count[label] += 1\n",
    "    return label_count\n",
    "\n",
    "label_count = count_labels(test_data)\n",
    "label_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_name 45\n",
      "a_organisation 20\n",
      "a_place 20\n"
     ]
    }
   ],
   "source": [
    "from utils import create_test_data_for_label\n",
    "\n",
    "# create test data for each specific labels\n",
    "labelled_test_data = dict() \n",
    "for label in all_test_labels:\n",
    "    labelled_test_data[label] = create_test_data_for_label(test_data, label)\n",
    "\n",
    "for k,v in labelled_test_data.items():\n",
    "    print(k, len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokenized_text': ['Thomas',\n",
       "  'arbeitet',\n",
       "  'bei',\n",
       "  'der',\n",
       "  'SBB',\n",
       "  'in',\n",
       "  'Aarau',\n",
       "  '.',\n",
       "  'Er',\n",
       "  'wurde',\n",
       "  'vor',\n",
       "  'kurzem',\n",
       "  'nach',\n",
       "  'Sch',\n",
       "  'ö',\n",
       "  'nenwerd',\n",
       "  'versetzt',\n",
       "  '.'],\n",
       " 'ner': [[6, 6, 'a_place'], [13, 15, 'a_place']]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_test_data['a_place'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: a_name, Results: P: 80.95%\tR: 47.22%\tF1: 59.65%\n",
      "\n",
      "Label: a_organisation, Results: P: 11.76%\tR: 9.52%\tF1: 10.53%\n",
      "\n",
      "Label: a_place, Results: P: 64.29%\tR: 31.03%\tF1: 41.86%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run evaluation for each label\n",
    "results = {}\n",
    "\n",
    "for label, data in labelled_test_data.items():\n",
    "    results[label], f1 = model_anonv0.evaluate(data, flat_ner=True, threshold=0.5, batch_size=1, entity_types=[label])\n",
    "    print(f\"Label: {label}, Results: {results[label]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: a_name\n",
      "Label: a_organisation\n",
      "Results: P: 97.15%\tR: 99.09%\tF1: 98.11%\n",
      "\n",
      "Label: a_place\n",
      "Results: P: 88.28%\tR: 98.10%\tF1: 92.93%\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# run evaluation for each label\n",
    "results = {}\n",
    "\n",
    "for label, data in labelled_test_data.items():\n",
    "    threshold = 0.5\n",
    "    print(f\"Label: {label}\")\n",
    "    if label == \"a_name\":\n",
    "        continue\n",
    "    else:\n",
    "        threshold = 0.95\n",
    "    results[label], f1 = model_anonv0.evaluate(data, flat_ner=True, threshold=threshold, batch_size=1, entity_types=[label])\n",
    "    print(f\"Results: {results[label]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>La société Énergie Verte SA et l'association S...</td>\n",
       "      <td>[Énergie Verte SA, Solidarité Environnement, L...</td>\n",
       "      <td>[a_organisation, a_organisation, a_place]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Madame Claire Dupont et Monsieur Jean-Louis Ma...</td>\n",
       "      <td>[Claire Dupont, Jean-Louis Martin]</td>\n",
       "      <td>[a_name, a_name]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Un contrat a été signé entre l'organisation Mé...</td>\n",
       "      <td>[Médecins Sans Frontières, Conseil Municipal d...</td>\n",
       "      <td>[a_organisation, a_place]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Monsieur Paul Durand, représentant de l'associ...</td>\n",
       "      <td>[Paul Durand, Culture et Patrimoine]</td>\n",
       "      <td>[a_name, a_organisation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>La Fondation pour la Recherche Médicale et l'u...</td>\n",
       "      <td>[Fondation pour la Recherche Médicale, univers...</td>\n",
       "      <td>[a_organisation, a_organisation, a_place]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  La société Énergie Verte SA et l'association S...   \n",
       "1  Madame Claire Dupont et Monsieur Jean-Louis Ma...   \n",
       "2  Un contrat a été signé entre l'organisation Mé...   \n",
       "3  Monsieur Paul Durand, représentant de l'associ...   \n",
       "4  La Fondation pour la Recherche Médicale et l'u...   \n",
       "\n",
       "                                            entities  \\\n",
       "0  [Énergie Verte SA, Solidarité Environnement, L...   \n",
       "1                 [Claire Dupont, Jean-Louis Martin]   \n",
       "2  [Médecins Sans Frontières, Conseil Municipal d...   \n",
       "3               [Paul Durand, Culture et Patrimoine]   \n",
       "4  [Fondation pour la Recherche Médicale, univers...   \n",
       "\n",
       "                                      labels  \n",
       "0  [a_organisation, a_organisation, a_place]  \n",
       "1                           [a_name, a_name]  \n",
       "2                  [a_organisation, a_place]  \n",
       "3                   [a_name, a_organisation]  \n",
       "4  [a_organisation, a_organisation, a_place]  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "ood_data = dict()\n",
    "keys = ['french', 'german', 'italian']\n",
    "\n",
    "for key in keys:\n",
    "    ood_data[key] = pd.read_csv(f'data/{key}_ood.csv')\n",
    "    # read entities and labels with ast.literal_eval\n",
    "    ood_data[key]['entities'] = ood_data[key]['entities'].apply(lambda x: ast.literal_eval(x))\n",
    "    ood_data[key]['labels'] = ood_data[key]['labels'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "ood_data['french'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: french\n",
      "Text: Madame Anne Leroy et Monsieur Jacques Rolland ont été choisis pour présider le comité de l'événement.\n",
      "Predicted Entities:\n",
      "Anne Leroy => a_name\n",
      "Jacques Rolland => a_name\n",
      "True Entities:\n",
      "Anne Leroy\n",
      "Jacques Rolland\n",
      "\n",
      "\n",
      "Text: La collaboration entre le Parc National des Pyrénées et le Ministère de la Culture a été officialisée.\n",
      "Predicted Entities:\n",
      "True Entities:\n",
      "Parc National des Pyrénées\n",
      "Ministère de la Culture\n",
      "\n",
      "\n",
      "Text: Le contrat entre l'entreprise SolarFrance et la Région PACA a été finalisé.\n",
      "Predicted Entities:\n",
      "SolarFrance => a_organisation\n",
      "True Entities:\n",
      "SolarFrance\n",
      "Région PACA\n",
      "\n",
      "\n",
      "Text: Le groupe Développement Durable et la ville de Rouen ont validé leur partenariat pour l'année à venir.\n",
      "Predicted Entities:\n",
      "Développement Durable => a_organisation\n",
      "Rouen => a_place\n",
      "True Entities:\n",
      "Développement Durable\n",
      "ville de Rouen\n",
      "Rouen\n",
      "\n",
      "\n",
      "Text: Le contrat entre l'association Humanité et Progrès et l'Université de Strasbourg a été ratifié sans amendement.\n",
      "Predicted Entities:\n",
      "Strasbourg => a_place\n",
      "True Entities:\n",
      "Humanité et Progrès\n",
      "Université de Strasbourg\n",
      "Strasbourg\n",
      "\n",
      "\n",
      "Key: german\n",
      "Text: Herr Dr. Wolfgang Müller wurde als Ansprechpartner für das Projekt der Stadtverwaltung Düsseldorf benannt.\n",
      "Predicted Entities:\n",
      "Wolfgang Müller => a_name\n",
      "True Entities:\n",
      "Dr. Wolfgang Müller\n",
      "Stadtverwaltung Düsseldorf\n",
      "\n",
      "\n",
      "Text: Der Verein Naturfreunde Deutschland e.V. und die Umweltgruppe TerraVerde kooperieren bei einem nationalen Naturschutzprojekt.\n",
      "Predicted Entities:\n",
      "TerraVerde => a_organisation\n",
      "True Entities:\n",
      "Naturfreunde Deutschland e.V.\n",
      "Umweltgruppe TerraVerde\n",
      "\n",
      "\n",
      "Text: Zwischen Herrn Paul Schröder und der Gesundheitsgenossenschaft Nord eG wurde in Kiel ein Vertrag geschlossen.\n",
      "Predicted Entities:\n",
      "Paul Schröder => a_name\n",
      "True Entities:\n",
      "Paul Schröder\n",
      "Gesundheitsgenossenschaft Nord eG\n",
      "Kiel\n",
      "\n",
      "\n",
      "Text: Die Schulung für die Mitarbeiter der Gesundheitszentrum Nord GmbH findet in Frankfurt am Main statt.\n",
      "Predicted Entities:\n",
      "Gesundheitszentrum Nord => a_organisation\n",
      "True Entities:\n",
      "Gesundheitszentrum Nord GmbH\n",
      "Frankfurt am Main\n",
      "\n",
      "\n",
      "Text: Der Vertrag mit der Stiftung Kulturerbe und der Stadtverwaltung Bonn wurde offiziell anerkannt.\n",
      "Predicted Entities:\n",
      "Bonn => a_place\n",
      "True Entities:\n",
      "Stiftung Kulturerbe\n",
      "Stadtverwaltung Bonn\n",
      "\n",
      "\n",
      "Key: italian\n",
      "Text: L'associazione Cuore Verde e l'azienda AgroBio SRL hanno collaborato a un progetto agricolo a Firenze.\n",
      "Predicted Entities:\n",
      "AgroBio => a_organisation\n",
      "True Entities:\n",
      "Cuore Verde\n",
      "AgroBio SRL\n",
      "Firenze\n",
      "\n",
      "\n",
      "Text: La signora Silvia Riva, in rappresentanza della società InnovItalia SRL, ha approvato il progetto.\n",
      "Predicted Entities:\n",
      "Silvia Riva => a_name\n",
      "InnovItalia => a_organisation\n",
      "True Entities:\n",
      "Silvia Riva\n",
      "InnovItalia SRL\n",
      "\n",
      "\n",
      "Text: Il signor Giorgio Pugliese ha partecipato alla riunione come rappresentante di Energia Pulita SRL.\n",
      "Predicted Entities:\n",
      "Giorgio Pugliese => a_name\n",
      "Energia Pulita => a_organisation\n",
      "True Entities:\n",
      "Giorgio Pugliese\n",
      "Energia Pulita SRL\n",
      "\n",
      "\n",
      "Text: L'associazione Cultura per Tutti e il Comune di Firenze hanno lanciato un progetto educativo.\n",
      "Predicted Entities:\n",
      "Firenze => a_place\n",
      "True Entities:\n",
      "Cultura per Tutti\n",
      "Comune di Firenze\n",
      "Firenze\n",
      "\n",
      "\n",
      "Text: Il contratto tra la società BioItalia e il Comune di Torino è stato firmato senza modifiche.\n",
      "Predicted Entities:\n",
      "BioItalia => a_organisation\n",
      "True Entities:\n",
      "BioItalia\n",
      "Comune di Torino\n",
      "Torino\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# take 5 random samples from each ood dataset and test the model\n",
    "\n",
    "for key, data in ood_data.items():\n",
    "    print(f\"Key: {key}\")\n",
    "    data = data.sample(5)\n",
    "    for index, row in data.iterrows():\n",
    "        text = row['text']\n",
    "        labels = row['labels']\n",
    "        entities = model_anonv0.predict_entities(text, labels, threshold=0.5)\n",
    "        print(f\"Text: {text}\")\n",
    "        print(\"Predicted Entities:\")\n",
    "        for entity in entities:\n",
    "            print(entity[\"text\"], \"=>\", entity[\"label\"])\n",
    "        print(\"True Entities:\")\n",
    "        for entry in row['entities']:\n",
    "            print(entry)\n",
    "        print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dslab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
