{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cuda', index=0),\n",
       " ['a_name', 'a_organisation', 'a_place'],\n",
       " ['person', 'organization', 'place'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from gliner import GLiNER\n",
    "import torch\n",
    "# @title Fast Mertics\n",
    "\n",
    "# Load the test.json file\n",
    "with open('anon_data/test.json', 'r') as file:\n",
    "    test_data = json.load(file)\n",
    "\n",
    "with open('anon_data/test_data_baseline.json', 'r') as file:\n",
    "    test_data_baseline = json.load(file)\n",
    "\n",
    "\n",
    "# Extract all labels from each example\n",
    "\n",
    "def get_all_labels(data):\n",
    "    all_labels = []\n",
    "    for example in data:\n",
    "        ner_data = example.get(\"ner\", [])\n",
    "        for entity in ner_data:\n",
    "            label = entity[2]  # Assuming the label is the third element in the entity list\n",
    "            if label not in all_labels:\n",
    "                all_labels.append(label)\n",
    "    return all_labels\n",
    "\n",
    "all_test_labels = get_all_labels(test_data)\n",
    "all_test_baseline_labels = get_all_labels(test_data_baseline)\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device, all_test_labels, all_test_baseline_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "LocalEntryNotFoundError",
     "evalue": "Cannot find an appropriate cached snapshot folder for the specified revision on the local disk and outgoing traffic has been disabled. To enable repo look-ups and downloads online, pass 'local_files_only=False' as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLocalEntryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/mert/dslab/test.ipynb Cell 2\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B150.136.146.76/home/ubuntu/mert/dslab/test.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model_anonv0_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmodels/AnonymizerV0\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B150.136.146.76/home/ubuntu/mert/dslab/test.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m model_anonv0 \u001b[39m=\u001b[39m GLiNER\u001b[39m.\u001b[39;49mfrom_pretrained(model_anonv0_path, load_tokenizer\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, local_files_only\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B150.136.146.76/home/ubuntu/mert/dslab/test.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m model_anonv0 \u001b[39m=\u001b[39m model_anonv0\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/dslab/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/dslab/lib/python3.10/site-packages/huggingface_hub/hub_mixin.py:571\u001b[0m, in \u001b[0;36mModelHubMixin.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, force_download, resume_download, proxies, token, cache_dir, local_files_only, revision, **model_kwargs)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_hub_mixin_inject_config \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mconfig\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m model_kwargs:\n\u001b[1;32m    569\u001b[0m         model_kwargs[\u001b[39m\"\u001b[39m\u001b[39mconfig\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m config\n\u001b[0;32m--> 571\u001b[0m instance \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_from_pretrained(\n\u001b[1;32m    572\u001b[0m     model_id\u001b[39m=\u001b[39;49m\u001b[39mstr\u001b[39;49m(model_id),\n\u001b[1;32m    573\u001b[0m     revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    574\u001b[0m     cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    575\u001b[0m     force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    576\u001b[0m     proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    577\u001b[0m     resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    578\u001b[0m     local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    579\u001b[0m     token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m    580\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m    581\u001b[0m )\n\u001b[1;32m    583\u001b[0m \u001b[39m# Implicitly set the config as instance attribute if not already set by the class\u001b[39;00m\n\u001b[1;32m    584\u001b[0m \u001b[39m# This way `config` will be available when calling `save_pretrained` or `push_to_hub`.\u001b[39;00m\n\u001b[1;32m    585\u001b[0m \u001b[39mif\u001b[39;00m config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m (\u001b[39mgetattr\u001b[39m(instance, \u001b[39m\"\u001b[39m\u001b[39m_hub_mixin_config\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39min\u001b[39;00m (\u001b[39mNone\u001b[39;00m, {})):\n",
      "File \u001b[0;32m~/miniconda3/envs/dslab/lib/python3.10/site-packages/gliner/model.py:761\u001b[0m, in \u001b[0;36mGLiNER._from_pretrained\u001b[0;34m(cls, model_id, revision, cache_dir, force_download, proxies, resume_download, local_files_only, token, map_location, strict, load_tokenizer, resize_token_embeddings, load_onnx_model, onnx_model_file, compile_torch_model, session_options, _attn_implementation, max_length, max_width, post_fusion_schema, **model_kwargs)\u001b[0m\n\u001b[1;32m    759\u001b[0m model_dir \u001b[39m=\u001b[39m Path(model_id)  \u001b[39m# / \"pytorch_model.bin\"\u001b[39;00m\n\u001b[1;32m    760\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m model_dir\u001b[39m.\u001b[39mexists():\n\u001b[0;32m--> 761\u001b[0m     model_dir \u001b[39m=\u001b[39m snapshot_download(\n\u001b[1;32m    762\u001b[0m         repo_id\u001b[39m=\u001b[39;49mmodel_id,\n\u001b[1;32m    763\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    764\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    765\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    766\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    767\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    768\u001b[0m         token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m    769\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    770\u001b[0m     )\n\u001b[1;32m    771\u001b[0m model_file \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(model_dir, \u001b[39m\"\u001b[39m\u001b[39mmodel.safetensors\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    772\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(model_file):\n",
      "File \u001b[0;32m~/miniconda3/envs/dslab/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/dslab/lib/python3.10/site-packages/huggingface_hub/_snapshot_download.py:219\u001b[0m, in \u001b[0;36msnapshot_download\u001b[0;34m(repo_id, repo_type, revision, cache_dir, local_dir, library_name, library_version, user_agent, proxies, etag_timeout, force_download, token, local_files_only, allow_patterns, ignore_patterns, max_workers, tqdm_class, headers, endpoint, local_dir_use_symlinks, resume_download)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[39m# If we couldn't find the appropriate folder on disk, raise an error.\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[39mif\u001b[39;00m local_files_only:\n\u001b[0;32m--> 219\u001b[0m     \u001b[39mraise\u001b[39;00m LocalEntryNotFoundError(\n\u001b[1;32m    220\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot find an appropriate cached snapshot folder for the specified revision on the local disk and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    221\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39moutgoing traffic has been disabled. To enable repo look-ups and downloads online, pass \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    222\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlocal_files_only=False\u001b[39m\u001b[39m'\u001b[39m\u001b[39m as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    223\u001b[0m     )\n\u001b[1;32m    224\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(api_call_error, OfflineModeIsEnabled):\n\u001b[1;32m    225\u001b[0m     \u001b[39mraise\u001b[39;00m LocalEntryNotFoundError(\n\u001b[1;32m    226\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot find an appropriate cached snapshot folder for the specified revision on the local disk and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    227\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39moutgoing traffic has been disabled. To enable repo look-ups and downloads online, set \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    228\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mHF_HUB_OFFLINE=0\u001b[39m\u001b[39m'\u001b[39m\u001b[39m as environment variable.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mapi_call_error\u001b[39;00m\n",
      "\u001b[0;31mLocalEntryNotFoundError\u001b[0m: Cannot find an appropriate cached snapshot folder for the specified revision on the local disk and outgoing traffic has been disabled. To enable repo look-ups and downloads online, pass 'local_files_only=False' as input."
     ]
    }
   ],
   "source": [
    "model_anonv0_path = 'models_anonymizer/AnonymizerV0'\n",
    "\n",
    "model_anonv0 = GLiNER.from_pretrained(model_anonv0_path, load_tokenizer=True, local_files_only=True)\n",
    "model_anonv0 = model_anonv0.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.99\n",
      "P: 99.55%\tR: 99.24%\tF1: 99.40%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results, f1 = model_anonv0.evaluate(test_data, flat_ner=True, threshold=0.5, batch_size=1, entity_types=all_test_labels)\n",
    "output_info = f\"F1 Score: {f1:.2f}\" + \"\\n\" + results\n",
    "print(output_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66b72db1e86745428974b203340c2795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_baseline1 = GLiNER.from_pretrained('knowledgator/gliner-multitask-large-v0.5')\n",
    "model_baseline1 = model_baseline1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.43\n",
      "P: 32.30%\tR: 66.46%\tF1: 43.48%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results, f1 = model_baseline1.evaluate(test_data_baseline, flat_ner=True, threshold=0.5, batch_size=1, entity_types=all_test_baseline_labels)\n",
    "output_info = f\"F1 Score: {f1:.2f}\" + \"\\n\" + results\n",
    "print(output_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19769e77ba364c549ba10c78238d2b88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# urchade/gliner_multi_pii-v1\n",
    "model_baseline2 = GLiNER.from_pretrained('urchade/gliner_multi_pii-v1')\n",
    "model_baseline2 = model_baseline2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.43\n",
      "P: 31.75%\tR: 66.91%\tF1: 43.07%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results, f1 = model_baseline2.evaluate(test_data_baseline, flat_ner=True, threshold=0.5, batch_size=1, entity_types=all_test_baseline_labels)\n",
    "output_info = f\"F1 Score: {f1:.2f}\" + \"\\n\" + results\n",
    "print(output_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do Inference on one sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('11 ) unter anderem strafbar, wer sich die Marke eines anderen anmasst oder diese nachmacht oder nachahmt ( lit. a ) oder wer unter der angemassten, nachgemachten oder nachgeahmten Marke Waren in Verkehr setzt, solche Waren anbietet, ein -, aus - oder durchführt, sie zum Zweck des Inverkehrbringens lagert oder für sie wirbt ( lit. b ). Vor diesem Hintergrund ist nicht ohne Weiteres klar, worin das Interesse der Beschwerdeführerin an der Herausgabe dieser nur sehr begrenzt verkehrsfähigen Gegenstände liegen soll. Auch wenn sie als beschuldigte Person prinzipiell zur Beschwerde in Strafsachen legitimiert ist, hätte sie sich daher dazu äussern müssen, woraus sie ihr rechtlich geschütztes Interesse an der Anfechtung der Einziehungen ableitet. Wo sie nicht offensichtlich ist, bezieht sich die Begründungsobliegenheit von Art. 42 Abs. 2 BGG auch auf die Legitimation ( vgl. BGE 141 IV 1 E. 1. 1 mit Hinweisen; Urteil 7B_183 / 2023 vom 26. Juli 2023 E. 1. 3 ). Da die Beschwerdeführerin dieser Obliegenheit nicht nachkommt, erübrigt sich ein Eintreten auf die Beschwerde in diesem Punkt. 11. Schliesslich macht die Beschwerdeführerin auch hinsichtlich der Zivilansprüche in den Dossiers Michal Lutz und Belal Fernandez eine Verletzung der gehörsrechtlichen Begründungspflicht geltend. 11. 1. Im Fall Michal Lutz, so die Beschwerdeführerin konkret, befasse sich die Vorinstanz nicht mit ihrem Einwand, wonach die Zivilforderung ungenügend beziffert sei und Gesamthandsgemeinschaften übereinstimmende Rechtsbegehren stellen müssten. Gleiches gelte für den Einwand,',\n",
       " [[212, 213, 'a_name'], [230, 231, 'a_name'], [215, 216, 'a_name']])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def join_tokens(tokens):\n",
    "    # code from Gliner_Studio: https://colab.research.google.com/drive/1Kl3TrpiGBpMw569ek_AL6Ee3uqBK-Gfw?usp=sharing\n",
    "    # Joining tokens with space, but handling special characters correctly\n",
    "    text = \"\"\n",
    "    for token in tokens:\n",
    "        if token in {\",\", \".\", \"!\", \"?\", \":\", \";\", \"...\"}:\n",
    "            text = text.rstrip() + token\n",
    "        else:\n",
    "            text += \" \" + token\n",
    "    return text.strip()\n",
    "\n",
    "example_index = 0\n",
    "text = join_tokens(test_data[example_index][\"tokenized_text\"])\n",
    "text, test_data[example_index][\"ner\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_name: ['Michal', 'Lutz']\n",
      "a_name: ['Michal', 'Lutz']\n",
      "a_name: ['Belal', 'Fernandez']\n"
     ]
    }
   ],
   "source": [
    "def view(tokenized_text, ners):\n",
    "    for ner in ners:\n",
    "        start, end, label = ner\n",
    "        print(f\"{label}: {tokenized_text[start:end+1]}\")\n",
    "\n",
    "view(test_data[example_index][\"tokenized_text\"], test_data[example_index][\"ner\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a_name', 'a_organisation', 'a_place']\n",
      "Expected Entities:\n",
      "a_name: ['Chloé', 'Fendt-Newlin']\n",
      "a_name: ['Chloé', 'Fendt-Newlin']\n",
      "a_name: ['Chloé', 'Fendt-Newlin']\n",
      "a_name: ['Chloé', 'Fendt-Newlin']\n",
      "\n",
      "Predicted Entities:\n",
      "Chloé Fendt-Newlin => a_name\n",
      "Chloé Fendt-Newlin => a_name\n",
      "Chloé Fendt-Newlin => a_name\n",
      "Chloé Fendt-Newlin => a_name\n"
     ]
    }
   ],
   "source": [
    "example_index = 15\n",
    "\n",
    "text = join_tokens(test_data[example_index][\"tokenized_text\"])\n",
    "expected_ner = test_data[example_index][\"ner\"]\n",
    "\n",
    "# Labels for entity prediction\n",
    "labels = all_test_labels\n",
    "print(labels)\n",
    "\n",
    "# Perform entity prediction\n",
    "entities = model_anonv0.predict_entities(text, labels, threshold=0.5)\n",
    "\n",
    "# Display predicted entities and their labels\n",
    "print(\"Expected Entities:\")\n",
    "view(test_data[example_index][\"tokenized_text\"], test_data[example_index][\"ner\"])\n",
    "\n",
    "print(\"\\nPredicted Entities:\")\n",
    "for entity in entities:\n",
    "    print(entity[\"text\"], \"=>\", entity[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a_name': 49722, 'a_organisation': 6945, 'a_place': 1897}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count all labels in the test dataset\n",
    "def count_labels(data):\n",
    "    label_count = {}\n",
    "    for example in data:\n",
    "        ner_data = example.get(\"ner\", [])\n",
    "        for entity in ner_data:\n",
    "            label = entity[2]  # Assuming the label is the third element in the entity list\n",
    "            if label not in label_count:\n",
    "                label_count[label] = 0\n",
    "            label_count[label] += 1\n",
    "    return label_count\n",
    "\n",
    "label_count = count_labels(test_data)\n",
    "label_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_name 13902\n",
      "a_organisation 2817\n",
      "a_place 1121\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# create test data for each specific labels (filter data points for a specific label, throw out examples that do not have the label)\n",
    "def create_test_data_for_label(data, label):\n",
    "    test_data_label = []\n",
    "    for example in data:\n",
    "        ner_data = example.get(\"ner\", [])\n",
    "        new_ners = []\n",
    "        for entity in ner_data:\n",
    "            if entity[2] == label:\n",
    "                new_ners.append(entity)\n",
    "        if len(new_ners) > 0:\n",
    "            test_data_label.append({\"tokenized_text\": example[\"tokenized_text\"], \"ner\": new_ners})\n",
    "    return test_data_label\n",
    "\n",
    "# create test data for each specific labels\n",
    "labelled_test_data = dict() \n",
    "for label in all_test_labels:\n",
    "    labelled_test_data[label] = create_test_data_for_label(test_data, label)\n",
    "\n",
    "for k,v in labelled_test_data.items():\n",
    "    print(k, len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokenized_text': ['Participants',\n",
       "  'à',\n",
       "  'la',\n",
       "  'procédure',\n",
       "  'Stefan',\n",
       "  'Michaud',\n",
       "  ',',\n",
       "  'représenté',\n",
       "  'par',\n",
       "  'Me',\n",
       "  'Manuela',\n",
       "  'Ryter',\n",
       "  'Godel',\n",
       "  ',',\n",
       "  'avocate',\n",
       "  ',',\n",
       "  'recourant',\n",
       "  ',',\n",
       "  'contre',\n",
       "  'Ministère',\n",
       "  'public',\n",
       "  'central',\n",
       "  'du',\n",
       "  'canton',\n",
       "  'de',\n",
       "  'Vaud',\n",
       "  ',',\n",
       "  'avenue',\n",
       "  'de',\n",
       "  'Longemalle',\n",
       "  '1',\n",
       "  ',',\n",
       "  '1020',\n",
       "  'Renens',\n",
       "  'VD',\n",
       "  ',',\n",
       "  'intimé',\n",
       "  '.',\n",
       "  'Objet',\n",
       "  'Ordonnance',\n",
       "  'de',\n",
       "  'classement',\n",
       "  '(',\n",
       "  'mise',\n",
       "  'en',\n",
       "  'danger',\n",
       "  'de',\n",
       "  'la',\n",
       "  'vie',\n",
       "  'd',\n",
       "  \"'\",\n",
       "  'autrui',\n",
       "  ',',\n",
       "  'abus',\n",
       "  'd',\n",
       "  \"'\",\n",
       "  'autorité',\n",
       "  ')',\n",
       "  ',',\n",
       "  'recours',\n",
       "  'contre',\n",
       "  'l',\n",
       "  \"'\",\n",
       "  'arrêt',\n",
       "  'du',\n",
       "  'Tribunal',\n",
       "  'cantonal',\n",
       "  'du',\n",
       "  'canton',\n",
       "  'de',\n",
       "  'Vaud',\n",
       "  ',',\n",
       "  'Chambre',\n",
       "  'des',\n",
       "  'recours',\n",
       "  'pénale',\n",
       "  ',',\n",
       "  'du',\n",
       "  '17',\n",
       "  'février',\n",
       "  '2020',\n",
       "  '(',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '[',\n",
       "  'PE1',\n",
       "  ']',\n",
       "  ')',\n",
       "  '.',\n",
       "  'Faits',\n",
       "  ':',\n",
       "  'A',\n",
       "  '.',\n",
       "  'Le',\n",
       "  '7',\n",
       "  'mars',\n",
       "  '2019',\n",
       "  ',',\n",
       "  'à',\n",
       "  'Bottmingen',\n",
       "  ',',\n",
       "  'Kalia',\n",
       "  'Domenjoz',\n",
       "  'et',\n",
       "  'Stefan',\n",
       "  'Michaud',\n",
       "  ',',\n",
       "  'dans',\n",
       "  'une',\n",
       "  'BMW',\n",
       "  'grise',\n",
       "  'conduite',\n",
       "  'par',\n",
       "  'ce',\n",
       "  'dernier',\n",
       "  ',',\n",
       "  'ont',\n",
       "  'été',\n",
       "  'interpellés',\n",
       "  'dans',\n",
       "  'la',\n",
       "  'rue',\n",
       "  'du',\n",
       "  'Stand',\n",
       "  ',',\n",
       "  'qui',\n",
       "  'se',\n",
       "  'termine',\n",
       "  'en',\n",
       "  'cul-de-sac',\n",
       "  ',',\n",
       "  'après',\n",
       "  'avoir',\n",
       "  'été',\n",
       "  'suivis',\n",
       "  'depuis',\n",
       "  'le',\n",
       "  'centre',\n",
       "  'de',\n",
       "  'Bottmingen',\n",
       "  'par',\n",
       "  'la',\n",
       "  'patrouille',\n",
       "  'de',\n",
       "  'police',\n",
       "  'Sami',\n",
       "  'Brazerol',\n",
       "  ',',\n",
       "  'composée',\n",
       "  'des',\n",
       "  'agents',\n",
       "  'Léone',\n",
       "  'Martin',\n",
       "  'et',\n",
       "  'Yvonne',\n",
       "  'Grob',\n",
       "  '.',\n",
       "  'Les',\n",
       "  'deux',\n",
       "  'policiers',\n",
       "  'ont',\n",
       "  'fait',\n",
       "  'usage',\n",
       "  'de',\n",
       "  'leurs',\n",
       "  'armes',\n",
       "  '.',\n",
       "  'Ils',\n",
       "  'ont',\n",
       "  'ensuite',\n",
       "  'été',\n",
       "  'rejoints',\n",
       "  'par',\n",
       "  'une',\n",
       "  'autre',\n",
       "  'patrouille',\n",
       "  ',',\n",
       "  'composée',\n",
       "  'des',\n",
       "  'agents',\n",
       "  'Bernadette',\n",
       "  'Drees',\n",
       "  'et',\n",
       "  'Heinz',\n",
       "  'Eriksen',\n",
       "  '.',\n",
       "  'Le',\n",
       "  'même',\n",
       "  'jour',\n",
       "  ',',\n",
       "  'une',\n",
       "  'instruction',\n",
       "  'pénale',\n",
       "  'a',\n",
       "  'été',\n",
       "  'ouverte',\n",
       "  'sous',\n",
       "  'référence',\n",
       "  'PE2',\n",
       "  'par',\n",
       "  'le',\n",
       "  'Ministère',\n",
       "  'public',\n",
       "  'de',\n",
       "  'l',\n",
       "  \"'\",\n",
       "  'arrondissement',\n",
       "  'de',\n",
       "  'l',\n",
       "  \"'\",\n",
       "  'Est',\n",
       "  'vaudois',\n",
       "  'contre',\n",
       "  'Kalia',\n",
       "  'Domenjoz',\n",
       "  'et',\n",
       "  'Stefan',\n",
       "  'Michaud',\n",
       "  'en',\n",
       "  'raison',\n",
       "  'de',\n",
       "  'la',\n",
       "  'course-poursuite',\n",
       "  'qui',\n",
       "  's',\n",
       "  \"'\",\n",
       "  'est',\n",
       "  'déroulée',\n",
       "  'entre',\n",
       "  'le',\n",
       "  'centre',\n",
       "  'de',\n",
       "  'Bottmingen',\n",
       "  'et',\n",
       "  'la',\n",
       "  'rue',\n",
       "  'du',\n",
       "  'Stand',\n",
       "  '.',\n",
       "  'Lors',\n",
       "  'de',\n",
       "  'leurs',\n",
       "  'auditions',\n",
       "  'd',\n",
       "  \"'\",\n",
       "  'arrestation',\n",
       "  'respectives',\n",
       "  'du',\n",
       "  '9',\n",
       "  'mars',\n",
       "  '2019',\n",
       "  ',',\n",
       "  'Kalia',\n",
       "  'Domenjoz',\n",
       "  'et',\n",
       "  'Stefan',\n",
       "  'Michaud',\n",
       "  'ont',\n",
       "  'tous',\n",
       "  'deux',\n",
       "  'déposé',\n",
       "  'plainte',\n",
       "  '.',\n",
       "  'Stefan',\n",
       "  'Michaud'],\n",
       " 'ner': [[100, 100, 'a_place'], [140, 140, 'a_place'], [233, 233, 'a_place']]}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_test_data['a_place'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: a_name, Results: P: 99.78%\tR: 99.43%\tF1: 99.60%\n",
      "\n",
      "Label: a_organisation, Results: P: 96.70%\tR: 99.16%\tF1: 97.92%\n",
      "\n",
      "Label: a_place, Results: P: 83.95%\tR: 98.15%\tF1: 90.50%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run evaluation for each label\n",
    "results = {}\n",
    "\n",
    "for label, data in labelled_test_data.items():\n",
    "    results[label], f1 = model_anonv0.evaluate(data, flat_ner=True, threshold=0.5, batch_size=1, entity_types=[label])\n",
    "    print(f\"Label: {label}, Results: {results[label]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: a_name\n",
      "Label: a_organisation\n",
      "Results: P: 97.15%\tR: 99.09%\tF1: 98.11%\n",
      "\n",
      "Label: a_place\n",
      "Results: P: 88.28%\tR: 98.10%\tF1: 92.93%\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# run evaluation for each label\n",
    "results = {}\n",
    "\n",
    "for label, data in labelled_test_data.items():\n",
    "    threshold = 0.5\n",
    "    print(f\"Label: {label}\")\n",
    "    if label == \"a_name\":\n",
    "        continue\n",
    "    else:\n",
    "        threshold = 0.95\n",
    "    results[label], f1 = model_anonv0.evaluate(data, flat_ner=True, threshold=threshold, batch_size=1, entity_types=[label])\n",
    "    print(f\"Results: {results[label]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>La société Énergie Verte SA et l'association S...</td>\n",
       "      <td>[Énergie Verte SA, Solidarité Environnement, L...</td>\n",
       "      <td>[a_organisation, a_organisation, a_place]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Madame Claire Dupont et Monsieur Jean-Louis Ma...</td>\n",
       "      <td>[Claire Dupont, Jean-Louis Martin]</td>\n",
       "      <td>[a_name, a_name]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Un contrat a été signé entre l'organisation Mé...</td>\n",
       "      <td>[Médecins Sans Frontières, Conseil Municipal d...</td>\n",
       "      <td>[a_organisation, a_place]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Monsieur Paul Durand, représentant de l'associ...</td>\n",
       "      <td>[Paul Durand, Culture et Patrimoine]</td>\n",
       "      <td>[a_name, a_organisation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>La Fondation pour la Recherche Médicale et l'u...</td>\n",
       "      <td>[Fondation pour la Recherche Médicale, univers...</td>\n",
       "      <td>[a_organisation, a_organisation, a_place]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  La société Énergie Verte SA et l'association S...   \n",
       "1  Madame Claire Dupont et Monsieur Jean-Louis Ma...   \n",
       "2  Un contrat a été signé entre l'organisation Mé...   \n",
       "3  Monsieur Paul Durand, représentant de l'associ...   \n",
       "4  La Fondation pour la Recherche Médicale et l'u...   \n",
       "\n",
       "                                            entities  \\\n",
       "0  [Énergie Verte SA, Solidarité Environnement, L...   \n",
       "1                 [Claire Dupont, Jean-Louis Martin]   \n",
       "2  [Médecins Sans Frontières, Conseil Municipal d...   \n",
       "3               [Paul Durand, Culture et Patrimoine]   \n",
       "4  [Fondation pour la Recherche Médicale, univers...   \n",
       "\n",
       "                                      labels  \n",
       "0  [a_organisation, a_organisation, a_place]  \n",
       "1                           [a_name, a_name]  \n",
       "2                  [a_organisation, a_place]  \n",
       "3                   [a_name, a_organisation]  \n",
       "4  [a_organisation, a_organisation, a_place]  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "ood_data = dict()\n",
    "keys = ['french', 'german', 'italian']\n",
    "\n",
    "for key in keys:\n",
    "    ood_data[key] = pd.read_csv(f'data/{key}_ood.csv')\n",
    "    # read entities and labels with ast.literal_eval\n",
    "    ood_data[key]['entities'] = ood_data[key]['entities'].apply(lambda x: ast.literal_eval(x))\n",
    "    ood_data[key]['labels'] = ood_data[key]['labels'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "ood_data['french'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: french\n",
      "Text: Madame Anne Leroy et Monsieur Jacques Rolland ont été choisis pour présider le comité de l'événement.\n",
      "Predicted Entities:\n",
      "Anne Leroy => a_name\n",
      "Jacques Rolland => a_name\n",
      "True Entities:\n",
      "Anne Leroy\n",
      "Jacques Rolland\n",
      "\n",
      "\n",
      "Text: La collaboration entre le Parc National des Pyrénées et le Ministère de la Culture a été officialisée.\n",
      "Predicted Entities:\n",
      "True Entities:\n",
      "Parc National des Pyrénées\n",
      "Ministère de la Culture\n",
      "\n",
      "\n",
      "Text: Le contrat entre l'entreprise SolarFrance et la Région PACA a été finalisé.\n",
      "Predicted Entities:\n",
      "SolarFrance => a_organisation\n",
      "True Entities:\n",
      "SolarFrance\n",
      "Région PACA\n",
      "\n",
      "\n",
      "Text: Le groupe Développement Durable et la ville de Rouen ont validé leur partenariat pour l'année à venir.\n",
      "Predicted Entities:\n",
      "Développement Durable => a_organisation\n",
      "Rouen => a_place\n",
      "True Entities:\n",
      "Développement Durable\n",
      "ville de Rouen\n",
      "Rouen\n",
      "\n",
      "\n",
      "Text: Le contrat entre l'association Humanité et Progrès et l'Université de Strasbourg a été ratifié sans amendement.\n",
      "Predicted Entities:\n",
      "Strasbourg => a_place\n",
      "True Entities:\n",
      "Humanité et Progrès\n",
      "Université de Strasbourg\n",
      "Strasbourg\n",
      "\n",
      "\n",
      "Key: german\n",
      "Text: Herr Dr. Wolfgang Müller wurde als Ansprechpartner für das Projekt der Stadtverwaltung Düsseldorf benannt.\n",
      "Predicted Entities:\n",
      "Wolfgang Müller => a_name\n",
      "True Entities:\n",
      "Dr. Wolfgang Müller\n",
      "Stadtverwaltung Düsseldorf\n",
      "\n",
      "\n",
      "Text: Der Verein Naturfreunde Deutschland e.V. und die Umweltgruppe TerraVerde kooperieren bei einem nationalen Naturschutzprojekt.\n",
      "Predicted Entities:\n",
      "TerraVerde => a_organisation\n",
      "True Entities:\n",
      "Naturfreunde Deutschland e.V.\n",
      "Umweltgruppe TerraVerde\n",
      "\n",
      "\n",
      "Text: Zwischen Herrn Paul Schröder und der Gesundheitsgenossenschaft Nord eG wurde in Kiel ein Vertrag geschlossen.\n",
      "Predicted Entities:\n",
      "Paul Schröder => a_name\n",
      "True Entities:\n",
      "Paul Schröder\n",
      "Gesundheitsgenossenschaft Nord eG\n",
      "Kiel\n",
      "\n",
      "\n",
      "Text: Die Schulung für die Mitarbeiter der Gesundheitszentrum Nord GmbH findet in Frankfurt am Main statt.\n",
      "Predicted Entities:\n",
      "Gesundheitszentrum Nord => a_organisation\n",
      "True Entities:\n",
      "Gesundheitszentrum Nord GmbH\n",
      "Frankfurt am Main\n",
      "\n",
      "\n",
      "Text: Der Vertrag mit der Stiftung Kulturerbe und der Stadtverwaltung Bonn wurde offiziell anerkannt.\n",
      "Predicted Entities:\n",
      "Bonn => a_place\n",
      "True Entities:\n",
      "Stiftung Kulturerbe\n",
      "Stadtverwaltung Bonn\n",
      "\n",
      "\n",
      "Key: italian\n",
      "Text: L'associazione Cuore Verde e l'azienda AgroBio SRL hanno collaborato a un progetto agricolo a Firenze.\n",
      "Predicted Entities:\n",
      "AgroBio => a_organisation\n",
      "True Entities:\n",
      "Cuore Verde\n",
      "AgroBio SRL\n",
      "Firenze\n",
      "\n",
      "\n",
      "Text: La signora Silvia Riva, in rappresentanza della società InnovItalia SRL, ha approvato il progetto.\n",
      "Predicted Entities:\n",
      "Silvia Riva => a_name\n",
      "InnovItalia => a_organisation\n",
      "True Entities:\n",
      "Silvia Riva\n",
      "InnovItalia SRL\n",
      "\n",
      "\n",
      "Text: Il signor Giorgio Pugliese ha partecipato alla riunione come rappresentante di Energia Pulita SRL.\n",
      "Predicted Entities:\n",
      "Giorgio Pugliese => a_name\n",
      "Energia Pulita => a_organisation\n",
      "True Entities:\n",
      "Giorgio Pugliese\n",
      "Energia Pulita SRL\n",
      "\n",
      "\n",
      "Text: L'associazione Cultura per Tutti e il Comune di Firenze hanno lanciato un progetto educativo.\n",
      "Predicted Entities:\n",
      "Firenze => a_place\n",
      "True Entities:\n",
      "Cultura per Tutti\n",
      "Comune di Firenze\n",
      "Firenze\n",
      "\n",
      "\n",
      "Text: Il contratto tra la società BioItalia e il Comune di Torino è stato firmato senza modifiche.\n",
      "Predicted Entities:\n",
      "BioItalia => a_organisation\n",
      "True Entities:\n",
      "BioItalia\n",
      "Comune di Torino\n",
      "Torino\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# take 5 random samples from each ood dataset and test the model\n",
    "\n",
    "for key, data in ood_data.items():\n",
    "    print(f\"Key: {key}\")\n",
    "    data = data.sample(5)\n",
    "    for index, row in data.iterrows():\n",
    "        text = row['text']\n",
    "        labels = row['labels']\n",
    "        entities = model_anonv0.predict_entities(text, labels, threshold=0.5)\n",
    "        print(f\"Text: {text}\")\n",
    "        print(\"Predicted Entities:\")\n",
    "        for entity in entities:\n",
    "            print(entity[\"text\"], \"=>\", entity[\"label\"])\n",
    "        print(\"True Entities:\")\n",
    "        for entry in row['entities']:\n",
    "            print(entry)\n",
    "        print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dslab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
