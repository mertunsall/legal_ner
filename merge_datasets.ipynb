{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = f\"train_data_all\"\n",
    "finetune_path = f\"anon_data/train/\"\n",
    "citation_path = f\"citation_data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(train_path,f\"pile_mistral_v0.1_train.json\"),'r') as f:\n",
    "    data_pile = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(train_path,f\"urchadesynthetic-pii-ner-mistral-v1_train.json\"),'r') as f:\n",
    "    data_pii = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(train_path,f\"anon_train_empty.json\"),'r') as f:\n",
    "    anon_data_train_empty = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(train_path,f\"anon_train_non_empty.json\"),'r') as f:\n",
    "    anon_data_train_non_empty = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(train_path,f\"citation_train.json\"),'r') as f:\n",
    "    citation_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size pile-mistral :         15778\n",
      "size pii :                  15707\n",
      "size anon train empty :     564961\n",
      "size anon train n-empty :   303458\n",
      "size citation train data : 87760\n"
     ]
    }
   ],
   "source": [
    "print(f\"size pile-mistral :         {len(data_pile)}\")\n",
    "print(f\"size pii :                  {len(data_pii)}\")\n",
    "print(f\"size anon train empty :     {len(anon_data_train_empty)}\")\n",
    "print(f\"size anon train n-empty :   {len(anon_data_train_non_empty)}\")\n",
    "print(f\"size citation train data : {len(citation_data)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset mix = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data_pile-mistral : 90% of full dataset for training, 10% for testing -> 17.5K\n",
    "Data_pii : 90% of full dataset for training, 10% for testing -> 17.5K \n",
    "--> total pretrain data : 35K\n",
    "anon_data_train_non_empty:  randomly sample 10K\n",
    "anon_data_train_empty: randomly sample 10K\n",
    "citation_data: randomly sample 20K \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "merge_v1 = data_pile + data_pii + random.sample(anon_data_train_non_empty,10**4) + random.sample(anon_data_train_empty,10**4) + random.sample(citation_data,2*10**4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save merge_v1 dataset for finetuning\n",
    "\n",
    "with open(f\"finetune_data/merged_v1.json\",'w') as f:\n",
    "    json.dump(merge_v1,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset mix 2\n",
    "\n",
    "Don't include empty data in order to increase recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "merge_v2 = data_pile + data_pii + random.sample(anon_data_train_non_empty,10**4) + random.sample(citation_data,10**4)\n",
    "\n",
    "#save merge_v1 dataset for finetuning\n",
    "\n",
    "with open(f\"finetune_data/merged_v2.json\",'w') as f:\n",
    "    json.dump(merge_v2,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## anon_cit_v1\n",
    "\n",
    "25K anon + 25 K citation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "anon_cit_v1 = random.sample(anon_data_train_non_empty,25000) + random.sample(citation_data,25000)\n",
    "\n",
    "with open(f\"finetune_data/anon_cit_v1.json\",\"w\") as f:\n",
    "    json.dump(anon_cit_v1,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSL_NER",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
