{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "KOIfLRN54AgF"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "import importlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_names_data_path = f\"auxiliary_data/final/\"\n",
    "\n",
    "save_path = f\"anon_data/\"\n",
    "\n",
    "bge_data_path = f\"bge_data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k33OB01TnMaQ"
   },
   "source": [
    "load config and utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4331,
     "status": "ok",
     "timestamp": 1731080951475,
     "user": {
      "displayName": "Jonas Ruepp",
      "userId": "14771682256940670194"
     },
     "user_tz": -60
    },
    "id": "7ovk5-34nSWc",
    "outputId": "4b19b319-eba5-4597-b767-12b0b81e69e5"
   },
   "outputs": [],
   "source": [
    "with open(f\"config_synthetic_generation.yaml\",'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "#import the utils file -force reload\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "from utils import tokenize_text, join_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load random_generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random_name_samplers import RandomNameGenerator,RandomPlaceGenerator,RandomOrganisationGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1731080951476,
     "user": {
      "displayName": "Jonas Ruepp",
      "userId": "14771682256940670194"
     },
     "user_tz": -60
    },
    "id": "R9Lha8iLuFwZ",
    "outputId": "2d497ed4-9d76-45a5-856e-3acdf1b7c57e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'organization_endings': ['AG',\n",
       "  'GmbH',\n",
       "  'KG',\n",
       "  'OHG',\n",
       "  'e.K.',\n",
       "  'eK',\n",
       "  'UG',\n",
       "  'Inc.',\n",
       "  'Ltd.',\n",
       "  'Ltd',\n",
       "  'LLC',\n",
       "  'PLC',\n",
       "  'LP',\n",
       "  'LLP',\n",
       "  'SA',\n",
       "  'SARL',\n",
       "  'Sàrl',\n",
       "  'SAS',\n",
       "  'SNC',\n",
       "  'EURL',\n",
       "  'S.p.A.',\n",
       "  'S.r.l.',\n",
       "  'S.a.p.a.',\n",
       "  'S.n.c.',\n",
       "  'S.a.s.',\n",
       "  'SpA',\n",
       "  'Srl',\n",
       "  'Sapa',\n",
       "  'Sas'],\n",
       " 'cutoff': {'start_keywords': ['Participants à la procédure',\n",
       "   'Parteien',\n",
       "   'Verfahrensbeteiligte',\n",
       "   'Partecipanti al procedimento',\n",
       "   'Parties'],\n",
       "  'end_keywords': ['Lausanne', 'Losanna']}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rV9iLniLMF-x"
   },
   "source": [
    "# Function declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "lNrfHpEnZXzk"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "# Define a function to manipulate the text\n",
    "def cutoff_clear_names(text):\n",
    "    # Define the patterns for the start and end keywords\n",
    "    start_keywords = config['cutoff']['start_keywords']\n",
    "    end_keywords = config['cutoff']['end_keywords']\n",
    "\n",
    "    # Create the regex pattern for the start keywords\n",
    "    start_pattern = r'|'.join(re.escape(kw) for kw in start_keywords)\n",
    "\n",
    "    # Create the regex pattern for the end keywords\n",
    "    end_pattern = r'|'.join(re.escape(kw) for kw in end_keywords)\n",
    "\n",
    "    # Find the start position\n",
    "    start_match = re.search(start_pattern, text)\n",
    "    if start_match:\n",
    "        start_pos = start_match.start()\n",
    "    else:\n",
    "        start_pos = 0  # Start from the beginning if no match is found\n",
    "\n",
    "    # Find the end position\n",
    "    end_match = list(re.finditer(end_pattern, text)) #modification re.search -> re.finditer for cases where Lausanne appears as a place somewhere in the text and not only at the end\n",
    "    if end_match:\n",
    "        end_pos = end_match[-1].end()\n",
    "    else:\n",
    "        end_pos = len(text)  # End at the last character if no match is found\n",
    "\n",
    "    # Extract the relevant text\n",
    "    return text[start_pos:end_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "wK0Oam8Gt_Fr"
   },
   "outputs": [],
   "source": [
    "# Function to remove non-letter characters from the start and end\n",
    "def strip_non_letters(text : str) -> str:\n",
    "    text = text.strip()\n",
    "    return re.sub(r\"^[^a-zA-Z]+|[^a-zA-Z]+$\", \"\", text)\n",
    "\n",
    "\n",
    "def text_token_to_label_matching(tokenized_text,ner):\n",
    "  for ner_tag in ner:\n",
    "    start_index = ner_tag[0]\n",
    "    end_index = ner_tag[1]\n",
    "    print(f\"{tokenized_text[start_index:end_index+1]} -> {ner_tag[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "XlFC6aULlaIg"
   },
   "outputs": [],
   "source": [
    "def replace_entities(original_text : str, entity_to_name_mapping : dict) -> str:\n",
    "    # Collect all start and end positions with their replacement text\n",
    "    replacements = []\n",
    "    for entity, name in entity_to_name_mapping.items():\n",
    "        for match in re.finditer(re.escape(entity), original_text):  # Escape entities to handle special characters\n",
    "            replacements.append((match.start(), match.end(), name))\n",
    "\n",
    "    # Sort replacements by start position\n",
    "    replacements = sorted(replacements, key=lambda x: x[0])\n",
    "\n",
    "    # Build the modified text\n",
    "    modified_text = []\n",
    "    last_pos = 0\n",
    "    for start, end, name in replacements:\n",
    "        # Append unchanged text since the last match, then the replacement\n",
    "        modified_text.append(original_text[last_pos:start])\n",
    "        modified_text.append(name + \" \") #we add a white-space to resolve A.________SA -> JelmoliSA -> tokenize(JelmoliSA) = JelsomliSA != Jelmoli in subsequent token matching\n",
    "        last_pos = end\n",
    "\n",
    "    # Append any remaining text after the last replacement\n",
    "    modified_text.append(original_text[last_pos:])\n",
    "\n",
    "    return ''.join(modified_text)\n",
    "\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "def get_ner_labels(tokenized_modified_text : list, entity_to_name_mapping : dict, entity_to_label_mapping : dict) -> list[list]:\n",
    "\n",
    "  # Tokenize the names in the entity_to_name_mapping dict\n",
    "  synthetic_tokens = {entity : tokenize_text(name) for entity,name in entity_to_name_mapping.items()}\n",
    "\n",
    "  # convert to array\n",
    "  tokenized_modified_text_array = np.array(tokenized_modified_text)\n",
    "\n",
    "  ner_tags = []\n",
    "\n",
    "  for entity, tokens in synthetic_tokens.items():\n",
    "        # convert to array\n",
    "        tokens_array = np.array(tokens)\n",
    "        # Sliding window over tokenized_modified_text\n",
    "        window_view = sliding_window_view(tokenized_modified_text_array, len(tokens))\n",
    "\n",
    "        # Use np.all() with np.argwhere() to find matching windows\n",
    "        matching_indices = np.argwhere(np.all(window_view == tokens_array, axis=1)).flatten()\n",
    "\n",
    "        # Add NER tags based on the matching indices\n",
    "        for start_index in matching_indices:\n",
    "            end_index = start_index + len(tokens) - 1\n",
    "            ner_label = entity_to_label_mapping[entity]\n",
    "            ner_tags.append([int(start_index), int(end_index), ner_label]) #convert to int to allow for JSON serializability\n",
    "\n",
    "  return ner_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "y-Ra9jfrawah"
   },
   "outputs": [],
   "source": [
    "def anonymized_text_to_training_data(original_text : str, name_generator : RandomNameGenerator, place_generator : RandomPlaceGenerator, organisation_generator : RandomOrganisationGenerator,verbose=False) -> dict:\n",
    "\n",
    "    # Regex to find anonymized entities (e.g., A.________, AB.________AG, aaa.________ AG), which all contain exactly 8 underscores, followed by maybe a organisation indicator like AG\n",
    "    #anonymized_pattern = r\"(\\S+)_{8}\"\n",
    "    #anonymized_pattern = r\"(\\S+_{8})(?:\\s*(\\S+))?\" #modifications + -> *\n",
    "    anonymized_pattern = r\"([a-zA-Z]\\S*_{8})(?:\\s*(\\S+))?\"\n",
    "\n",
    "    # Organization indicators\n",
    "    organization_indicators = config['organization_endings']\n",
    "\n",
    "    #strip non-alphabetic characters from organisations indicators\n",
    "    organization_indicators = [strip_non_letters(indicator).lower() for indicator in organization_indicators] #lowercase\n",
    "\n",
    "    entity_to_label_mapping = {}\n",
    "\n",
    "    entity_to_suffix_mapping = {}\n",
    "\n",
    "    for match in re.finditer(anonymized_pattern,original_text):\n",
    "      entity = match.group(1) # returns the anonymized part ([a-zA-Z]\\S*_{8})\n",
    "      pre_suffix = match.group(2) # returns the next group of non-whitespace characters following the 8 underscores after one or more white-space characters, if applicable.\n",
    "\n",
    "      # Skip entities that are already categorized\n",
    "      if entity in entity_to_label_mapping.keys():\n",
    "        continue\n",
    "\n",
    "      #Check if entity represents a place:\n",
    "      if entity[0] in [\"U\",\"V\",\"W\"] and entity.endswith(\".________\"):\n",
    "        entity_to_label_mapping[entity] = 'location'\n",
    "\n",
    "      elif pre_suffix and strip_non_letters(pre_suffix).lower() in organization_indicators:\n",
    "        entity_to_label_mapping[entity] = 'organization'\n",
    "        suffix = strip_non_letters(pre_suffix)\n",
    "        entity_to_suffix_mapping[entity] = suffix\n",
    "\n",
    "      else: entity_to_label_mapping[entity] = 'person'\n",
    "\n",
    "    unique_entities = list(entity_to_label_mapping.keys())\n",
    "    unique_name_entities = [entity for entity,label in entity_to_label_mapping.items() if label == 'person']\n",
    "    unique_place_entities = [entity for entity,label in entity_to_label_mapping.items() if label == 'location']\n",
    "    unique_orga_entities = [entity for entity,label in entity_to_label_mapping.items() if label == 'organization']\n",
    "\n",
    "    # Create unique synthetic name\n",
    "    synthetic_names = set()\n",
    "    while len(synthetic_names) < len(unique_name_entities):\n",
    "      synthetic_names.add(name_generator.get_first_name_last_name_string())\n",
    "    synthetic_names = list(synthetic_names)\n",
    "\n",
    "    # Create synthetic places\n",
    "    synthetic_places = set()\n",
    "    while len(synthetic_places) < len(unique_place_entities):\n",
    "      synthetic_places.add(place_generator.get_place_string())\n",
    "    synthetic_places = list(synthetic_places)\n",
    "\n",
    "    # Create synthetic organisations\n",
    "    synthetic_orgas = set()\n",
    "    while len(synthetic_orgas) < len(unique_orga_entities):\n",
    "      synthetic_orgas.add(organisation_generator.get_organisation_string())\n",
    "    synthetic_orgas = list(synthetic_orgas)\n",
    "\n",
    "    #order unique_entities to names, places, organisations\n",
    "    unique_entities = unique_name_entities + unique_place_entities + unique_orga_entities\n",
    "\n",
    "    #order synthetic to names, places, organisations\n",
    "    synthetic = synthetic_names + synthetic_places + synthetic_orgas\n",
    "\n",
    "    # Create a mapping of anonymized entities to synthetic names\n",
    "    entity_to_name_mapping = dict(zip(unique_entities,synthetic))\n",
    "\n",
    "    #get modified text\n",
    "    modified_text = replace_entities(original_text,entity_to_name_mapping)\n",
    "\n",
    "    # tokenize modified text\n",
    "    tokenized_modified_text = tokenize_text(modified_text)\n",
    "\n",
    "    #get ner_tags\n",
    "    ner_tags = get_ner_labels(tokenized_modified_text,entity_to_name_mapping,entity_to_label_mapping)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Entity to label mapping: {entity_to_label_mapping}\")\n",
    "        print(f\"Entity to suffix mapping: {entity_to_suffix_mapping}\")\n",
    "        print(f\"Synthetic names: {synthetic_names}\")\n",
    "        print(f\"Synthetic places: {synthetic_places}\")\n",
    "        print(f\"Synthetic organisations: {synthetic_orgas}\")\n",
    "        print(f\"Entity to name mapping: {entity_to_name_mapping}\")\n",
    "\n",
    "\n",
    "    # Output structure\n",
    "    output = {\n",
    "        \"tokenized_text\": tokenized_modified_text,\n",
    "        \"ner\": ner_tags\n",
    "    }\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2aXPFTKrgYPn"
   },
   "source": [
    "# Initialize random name generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4Xer6cq0E-X"
   },
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 565,
     "status": "ok",
     "timestamp": 1731080952027,
     "user": {
      "displayName": "Jonas Ruepp",
      "userId": "14771682256940670194"
     },
     "user_tz": -60
    },
    "id": "tIsWrx6u2Efg",
    "outputId": "09e05f59-c1b7-4a3d-fe4a-9cc42b79eb68"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First_name</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64972</th>\n",
       "      <td>Zorina</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8363</th>\n",
       "      <td>Benyounes</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15242</th>\n",
       "      <td>Edwige</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48408</th>\n",
       "      <td>Relu</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34703</th>\n",
       "      <td>Lynette</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      First_name  count\n",
       "64972     Zorina      6\n",
       "8363   Benyounes      5\n",
       "15242     Edwige    193\n",
       "48408       Relu      6\n",
       "34703    Lynette     53"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_names_df = pd.read_csv(raw_names_data_path + f\"first_names_count.csv\")\n",
    "#drop rows where one or more values are nan\n",
    "first_names_df = first_names_df.dropna()\n",
    "first_names_df.sample(5,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1731080952029,
     "user": {
      "displayName": "Jonas Ruepp",
      "userId": "14771682256940670194"
     },
     "user_tz": -60
    },
    "id": "gFarlGCY5FQH",
    "outputId": "8fbd5f45-1ee0-487b-ba89-de2fefc14f53"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Last_name</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>226418</th>\n",
       "      <td>Ruckelshausen</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192985</th>\n",
       "      <td>Benkorachi</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10390</th>\n",
       "      <td>Polanco</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224473</th>\n",
       "      <td>Putta</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196196</th>\n",
       "      <td>Cardwell</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Last_name  count\n",
       "226418  Ruckelshausen      3\n",
       "192985     Benkorachi      3\n",
       "10390         Polanco    113\n",
       "224473          Putta      3\n",
       "196196       Cardwell      3"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_names_df = pd.read_csv(raw_names_data_path + f\"last_names_count.csv\")\n",
    "last_names_df = last_names_df.dropna(how = 'any')\n",
    "last_names_df.sample(5,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1731080952029,
     "user": {
      "displayName": "Jonas Ruepp",
      "userId": "14771682256940670194"
     },
     "user_tz": -60
    },
    "id": "T6xiqT1K0Ih0",
    "outputId": "a2aee823-1332-4111-a5c4-2d30782a955b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19439</th>\n",
       "      <td>Dürr Ecoclean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80509</th>\n",
       "      <td>Sintex Servizi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294159</th>\n",
       "      <td>Parva Domus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204275</th>\n",
       "      <td>Cse-Guide.Fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44723</th>\n",
       "      <td>Istituto Luce-Cinecitta  Societa  A Responsabi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     name\n",
       "19439                                       Dürr Ecoclean\n",
       "80509                                      Sintex Servizi\n",
       "294159                                        Parva Domus\n",
       "204275                                       Cse-Guide.Fr\n",
       "44723   Istituto Luce-Cinecitta  Societa  A Responsabi..."
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_names_df = pd.read_csv(raw_names_data_path + f\"organization_names.csv\")\n",
    "company_names_df = company_names_df.dropna(how = 'any')\n",
    "company_names_df.loc[:, 'name'] = company_names_df['name'].str.title()\n",
    "company_names_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1731080952030,
     "user": {
      "displayName": "Jonas Ruepp",
      "userId": "14771682256940670194"
     },
     "user_tz": -60
    },
    "id": "OfL_jJFqi4tY",
    "outputId": "09d98dfc-7dbf-4e9d-8f55-e6b56ed545cd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8134</th>\n",
       "      <td>Spoleto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6126</th>\n",
       "      <td>Arsac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4182</th>\n",
       "      <td>Derendingen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2380</th>\n",
       "      <td>Basel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>Schmölln</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name\n",
       "8134      Spoleto\n",
       "6126        Arsac\n",
       "4182  Derendingen\n",
       "2380        Basel\n",
       "1974     Schmölln"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "place_names_df = pd.read_csv(raw_names_data_path + f\"location_names.csv\")\n",
    "place_names_df = place_names_df.dropna(how = 'any')\n",
    "place_names_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "R5zNNmoMMbxL"
   },
   "outputs": [],
   "source": [
    "#initialize the generators\n",
    "name_generator = RandomNameGenerator(first_names_df,last_names_df,random_state = 42)\n",
    "place_generator = RandomPlaceGenerator(place_names_df,random_state = 42)\n",
    "organisation_generator = RandomOrganisationGenerator(company_names_df,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UHuEdgkPa2A5"
   },
   "source": [
    "# Apply Function to Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "error",
     "timestamp": 1731067738819,
     "user": {
      "displayName": "Jonas Ruepp",
      "userId": "14771682256940670194"
     },
     "user_tz": -60
    },
    "id": "X09KCEaf6d3P",
    "outputId": "394fbf45-f12b-4647-e3ee-3a7136d373a1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124089/124089 [2:40:40<00:00, 12.87it/s]       \n"
     ]
    }
   ],
   "source": [
    "#Save as JSON\n",
    "\n",
    "#first load the dataset df\n",
    "df = pd.read_parquet(os.path.join(bge_data_path,\"bger-2024-2-text.parquet\"))\n",
    "\n",
    "#only keep the \"text\" column\n",
    "df = df[['text']]\n",
    "\n",
    "#apply cutoff_clear_names and change column name to \"text_cutoff\"\n",
    "df['text'] = df['text'].apply(cutoff_clear_names)\n",
    "df.rename(columns={'text': 'text_cutoff'}, inplace=True)\n",
    "\n",
    "#apply anonymized_text_to_training_data to all text in df['text_cutoff'] and save the resulting list of dicts to json\n",
    "\n",
    "#use a for loop with tqdm to track progress\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Open the output JSON file in write mode\n",
    "with open(save_path + \"None\", 'w') as f:  #Enter valid filename\n",
    "    # Write the opening bracket for the JSON array\n",
    "    f.write('[')\n",
    "\n",
    "    # Process the DataFrame row by row\n",
    "    for i, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        # Call anonymized_text_to_training_data for the current row\n",
    "        training_data = anonymized_text_to_training_data(\n",
    "            row['text_cutoff'], name_generator, place_generator, organisation_generator\n",
    "        )\n",
    "\n",
    "        # Dump the training data to the JSON file\n",
    "        json.dump(training_data, f, separators=(',', ':'))\n",
    "\n",
    "        # Add a comma if it's not the last row\n",
    "        if i < df.shape[0] - 1:\n",
    "            f.write(',')\n",
    "\n",
    "    # Write the closing bracket for the JSON array\n",
    "    f.write(']')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1Kh7m3Y2mBJWyWQVR483SOaQs2l8zCGbA",
     "timestamp": 1730105519727
    },
    {
     "file_id": "1OBJ6f0DlM5rhY5H4M36WLf7dHEzW7E2l",
     "timestamp": 1729865147672
    }
   ]
  },
  "kernelspec": {
   "display_name": "DSL_NER",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
